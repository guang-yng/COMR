{
    "model_type": "gpt2",
    "vocab_size": 2048,
    "n_positions": 2048,
    "n_embd": 256,
    "n_layer": 8,
    "n_head": 4,
    "n_inner": 256,
    "activation_function": "relu",
    "bos_token_id": 1,
    "eos_token_id": 2
}